{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Submitted By:\n",
        "### Asad Tariq 19I-0659\n",
        "### Abdullah Abbasi 19I-2179\n",
        "### Saim Aslam 19I-0461"
      ],
      "metadata": {
        "id": "obhRqry_gQYN"
      },
      "id": "obhRqry_gQYN"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3d25648e",
      "metadata": {
        "id": "3d25648e"
      },
      "outputs": [],
      "source": [
        "\n",
        "import datetime\n",
        "import time\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import json\n",
        "from pathlib import Path\n",
        "import re\n",
        "import random\n",
        "import inflect\n",
        "import numpy as np\n",
        "import os\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAxvCTgsub-7",
        "outputId": "97d7d4ee-118d-466f-e428-0cd3094039ef"
      },
      "id": "rAxvCTgsub-7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m111.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c92e5123",
      "metadata": {
        "id": "c92e5123"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, GPT2Config, AdamW, get_linear_schedule_with_warmup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b679d1d0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b679d1d0",
        "outputId": "d3db8f9f-fd65-441d-dcf9-498e8acc9a34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: torch\n",
            "Version: 2.0.0+cu118\n",
            "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
            "Home-page: https://pytorch.org/\n",
            "Author: PyTorch Team\n",
            "Author-email: packages@pytorch.org\n",
            "License: BSD-3\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: filelock, jinja2, networkx, sympy, triton, typing-extensions\n",
            "Required-by: fastai, torchaudio, torchdata, torchtext, torchvision, triton\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "torch.manual_seed(64)\n",
        "from torch.utils.data import Dataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
        "!pip show torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04d66abb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04d66abb",
        "outputId": "3e48114c-0d13-4435-ebc5-d24b4b2d71a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "N0ry-rO1vCq_"
      },
      "id": "N0ry-rO1vCq_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d55fa70",
      "metadata": {
        "id": "0d55fa70"
      },
      "outputs": [],
      "source": [
        "\n",
        "nRowsRead = None # specify 'None' if want to read whole file\n",
        "#df = pd.read_csv('INPUT/all_haiku.csv', delimiter=',', nrows = nRowsRead)\n",
        "df=pd.read_csv('/content/gdrive/MyDrive/Work/all_haiku.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75246fc8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75246fc8",
        "outputId": "85bf3067-2c2a-4fc9-cc51-d94289d837a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 144123 rows and 6 columns\n"
          ]
        }
      ],
      "source": [
        "\n",
        "df.dataframeName = 'all_haiku.csv'\n",
        "nRow, nCol = df.shape\n",
        "print(f'There are {nRow} rows and {nCol} columns')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccbbdb0e",
      "metadata": {
        "id": "ccbbdb0e"
      },
      "outputs": [],
      "source": [
        "df=df.drop('Unnamed: 0',axis=1)\n",
        "df=df.drop('source',axis=1)\n",
        "df=df.drop('hash',axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cd8668b",
      "metadata": {
        "id": "9cd8668b"
      },
      "outputs": [],
      "source": [
        "df[\"2\"] = df[\"2\"].astype(str)\n",
        "df[\"2\"] = [x.replace('-','') for x in df[\"2\"]]\n",
        "df = df.replace('[^\\w\\s]', '')\n",
        "df = df.replace('-','',regex=True)\n",
        "df.rename(columns = {'0':0,'1':1,'2':2}, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2835278",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "a2835278",
        "outputId": "ba9f11e1-d333-4fff-bf7b-84cff76b64fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     0                                  1                 2\n",
              "0        fishing boats                          colors of       the rainbow\n",
              "1        ash wednesday                trying to remember           my dream\n",
              "2           snowy morn                pouring another cup   of black coffee\n",
              "3         shortest day                       flames dance       in the oven\n",
              "4                 haze              half the horse hidden  behind the house\n",
              "5              low sun                    the lady in red     on high heels\n",
              "6               advent               the passing stranger             farts\n",
              "7                 tarn                        a bubble in           the ice\n",
              "8           snowflakes                        new asphalt      in the holes\n",
              "9       Crystal Night'                      gusts of rain           outside\n",
              "10                rain     the sound of a horse galloping    through leaves\n",
              "11        winter stars                   suddenly a whiff        of perfume\n",
              "12              hungry                   half of the moon            hidden\n",
              "13                rain                       another leaf              down\n",
              "14              sharia              the sound of one hand          clapping\n",
              "15  the sound of geese  drowned by the sound of the train      this morning\n",
              "16          autumn sun                     my shadow over        tombstones\n",
              "17        fly fishing;              the sound of the wind       in the reel\n",
              "18            december                      a long shadow     joins another\n",
              "19         end of path                 snowflakes melting       on the pond"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-548de035-9a75-4e21-b7ce-6ec4f6095d71\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>fishing boats</td>\n",
              "      <td>colors of</td>\n",
              "      <td>the rainbow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ash wednesday</td>\n",
              "      <td>trying to remember</td>\n",
              "      <td>my dream</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>snowy morn</td>\n",
              "      <td>pouring another cup</td>\n",
              "      <td>of black coffee</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>shortest day</td>\n",
              "      <td>flames dance</td>\n",
              "      <td>in the oven</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>haze</td>\n",
              "      <td>half the horse hidden</td>\n",
              "      <td>behind the house</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>low sun</td>\n",
              "      <td>the lady in red</td>\n",
              "      <td>on high heels</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>advent</td>\n",
              "      <td>the passing stranger</td>\n",
              "      <td>farts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>tarn</td>\n",
              "      <td>a bubble in</td>\n",
              "      <td>the ice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>snowflakes</td>\n",
              "      <td>new asphalt</td>\n",
              "      <td>in the holes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Crystal Night'</td>\n",
              "      <td>gusts of rain</td>\n",
              "      <td>outside</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>rain</td>\n",
              "      <td>the sound of a horse galloping</td>\n",
              "      <td>through leaves</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>winter stars</td>\n",
              "      <td>suddenly a whiff</td>\n",
              "      <td>of perfume</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>hungry</td>\n",
              "      <td>half of the moon</td>\n",
              "      <td>hidden</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>rain</td>\n",
              "      <td>another leaf</td>\n",
              "      <td>down</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>sharia</td>\n",
              "      <td>the sound of one hand</td>\n",
              "      <td>clapping</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>the sound of geese</td>\n",
              "      <td>drowned by the sound of the train</td>\n",
              "      <td>this morning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>autumn sun</td>\n",
              "      <td>my shadow over</td>\n",
              "      <td>tombstones</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>fly fishing;</td>\n",
              "      <td>the sound of the wind</td>\n",
              "      <td>in the reel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>december</td>\n",
              "      <td>a long shadow</td>\n",
              "      <td>joins another</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>end of path</td>\n",
              "      <td>snowflakes melting</td>\n",
              "      <td>on the pond</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-548de035-9a75-4e21-b7ce-6ec4f6095d71')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-548de035-9a75-4e21-b7ce-6ec4f6095d71 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-548de035-9a75-4e21-b7ce-6ec4f6095d71');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "df.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acfa3855",
      "metadata": {
        "id": "acfa3855"
      },
      "outputs": [],
      "source": [
        "input_list=[]\n",
        "#for i in range(144123):\n",
        "for i in range(10000):\n",
        "    input_list.append(df[0][i]+'\\n'+df[1][i]+'\\n'+df[2][i]+'.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "457100a6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "457100a6",
        "outputId": "10c7769b-8908-4d25-c76c-5591debd657f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fishing boats\n",
            "colors of\n",
            "the rainbow.\n"
          ]
        }
      ],
      "source": [
        "print(input_list[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdf527e1",
      "metadata": {
        "id": "fdf527e1"
      },
      "outputs": [],
      "source": [
        "class HaikuDataset(Dataset):\n",
        "  def __init__(self, haikus, tokenizer, max_length=25, gpt2_type=\"gpt2\"):\n",
        "    self.tokenizer = tokenizer\n",
        "    self.input_ids = []\n",
        "    self.attn_masks = []\n",
        "\n",
        "    for haiku in haikus:\n",
        "\n",
        "      encodings_dict = tokenizer(\"<|startoftext|>\"+haiku+\"<|endoftext|>\",\n",
        "                                 truncation=True,\n",
        "                                 max_length=max_length,\n",
        "                                 padding=\"max_length\")\n",
        "      \n",
        "      self.input_ids.append(torch.tensor(encodings_dict[\"input_ids\"]))\n",
        "      self.attn_masks.append(torch.tensor(encodings_dict[\"attention_mask\"]))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.input_ids[idx], self.attn_masks[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aaec927f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaec927f",
        "outputId": "0800943e-f48c-40d6-b68a-bdcfdd980b08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "# Loading GPT2 Tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', \n",
        "                                          bos_token='<|startoftext|>', \n",
        "                                          eos_token='<|endoftext|>', \n",
        "                                          pad_token='<|pad|>')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cad46897",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cad46897",
        "outputId": "818d494b-4cb5-4c2d-e7ca-2c0abe0dc235"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50257, 18435, 2159, 220, 50256, 50258, 50258, 50258, 50258, 50258]\n",
            "50259\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.encode(\"<|startoftext|> Hello World <|endoftext|>\", padding=\"max_length\", max_length=10))\n",
        "print(len(tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abd13398",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abd13398",
        "outputId": "31094da3-5b4f-4f8c-9c52-930122cb3e32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500\n"
          ]
        }
      ],
      "source": [
        "# Finding length of maximum token in dataset\n",
        "max_length = max([len(tokenizer.encode(haiku)) for haiku in input_list])\n",
        "print(max_length)\n",
        "max_length = 25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71b67b30",
      "metadata": {
        "id": "71b67b30"
      },
      "outputs": [],
      "source": [
        "x = [len(tokenizer.encode(haiku)) for haiku in input_list if len(tokenizer.encode(haiku)) < 100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e28ddb91",
      "metadata": {
        "id": "e28ddb91"
      },
      "outputs": [],
      "source": [
        "y = [len(tokenizer.encode(haiku)) - len(haiku.split()) for haiku in input_list]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67c4592b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67c4592b",
        "outputId": "03d98777-c472-44eb-8952-c1b13f82118d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.7489\n"
          ]
        }
      ],
      "source": [
        "print(sum(y)/len(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0fd9eb6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "e0fd9eb6",
        "outputId": "302c72cd-6978-4378-dbf7-d2ec766d8173"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98 9950\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show(close=None, block=None)>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "print(max(x), len(x))\n",
        "plt.hist(x, bins = 5)\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fb5b1ee",
      "metadata": {
        "id": "5fb5b1ee"
      },
      "outputs": [],
      "source": [
        "batch_size = 10\n",
        "max_length = 25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3e4edb7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3e4edb7",
        "outputId": "de19205b-347b-43f1-d335-29745147e27e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples for training = 9000\n",
            "Number of samples for validation = 1000\n"
          ]
        }
      ],
      "source": [
        "dataset = HaikuDataset(input_list, tokenizer, max_length=max_length)\n",
        "\n",
        "# Split data into train and validation sets\n",
        "train_size = int(0.9*len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "print(\"Number of samples for training =\", train_size)\n",
        "print(\"Number of samples for validation =\", val_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "907e5ff7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "907e5ff7",
        "outputId": "40be7aef-743a-41ce-f005-75f63d31295c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([50257,    64, 14310,   198,  6236,  6448,   319,  4417,   198, 12853,\n",
              "          8824,    13, 50256, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
              "         50258, 50258, 50258, 50258, 50258]),\n",
              " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0]))"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "train_dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44394442",
      "metadata": {
        "id": "44394442"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(train_dataset,\n",
        "                              sampler=RandomSampler(train_dataset),\n",
        "                              batch_size=batch_size)\n",
        "\n",
        "val_dataloader = DataLoader(val_dataset,\n",
        "                            sampler=SequentialSampler(val_dataset),\n",
        "                            batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71e0d018",
      "metadata": {
        "id": "71e0d018"
      },
      "outputs": [],
      "source": [
        "# Load model configuration\n",
        "config = GPT2Config.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Create model instance and set embedding length\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", config=config)\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "# Running the model on GPU\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "091999e7",
      "metadata": {
        "id": "091999e7"
      },
      "outputs": [],
      "source": [
        "# Setting seeds to enable reproducible runs\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61a66f28",
      "metadata": {
        "id": "61a66f28"
      },
      "outputs": [],
      "source": [
        "epochs = 6\n",
        "warmup_steps = 1e2\n",
        "sample_every = 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "622ef68a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "622ef68a",
        "outputId": "1efae94c-f0d7-4742-ebd3-d30942db32f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "900\n",
            "9000\n"
          ]
        }
      ],
      "source": [
        "print(len(train_dataloader))\n",
        "print(len(train_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "166b4e87",
      "metadata": {
        "id": "166b4e87"
      },
      "outputs": [],
      "source": [
        "optimizer = AdamW(model.parameters(), lr=5e-4, eps=1e-8)\n",
        "\n",
        "# Toatl training steps is the number of data points times the number of epochs\n",
        "total_training_steps = len(train_dataloader)*epochs\n",
        "\n",
        "# Setting a variable learning rate using scheduler\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps=warmup_steps,\n",
        "                                            num_training_steps=total_training_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd2075a9",
      "metadata": {
        "id": "cd2075a9"
      },
      "outputs": [],
      "source": [
        "def format_time(elapsed):\n",
        "  return str(datetime.timedelta(seconds=int(round(elapsed))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27453737",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27453737",
        "outputId": "35998836-6150-4983-eac5-8cb2dc19c008"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beginning epoch 1 of 6\n",
            "Average Training Loss: 4.277013717227512. Epoch time: 0:01:35\n",
            "\n",
            "Validation loss: 3.4037511348724365. Validation Time: 0:00:03\n",
            "\n",
            "------------------------------\n",
            "Beginning epoch 2 of 6\n",
            "Average Training Loss: 3.008809403313531. Epoch time: 0:01:34\n",
            "\n",
            "Validation loss: 3.4731348633766173. Validation Time: 0:00:03\n",
            "\n",
            "------------------------------\n",
            "Beginning epoch 3 of 6\n",
            "Average Training Loss: 2.5131071000629. Epoch time: 0:01:34\n",
            "\n",
            "Validation loss: 3.6683690452575686. Validation Time: 0:00:02\n",
            "\n",
            "------------------------------\n",
            "Beginning epoch 4 of 6\n",
            "Average Training Loss: 1.9666119015216827. Epoch time: 0:01:34\n",
            "\n",
            "Validation loss: 4.026006355285644. Validation Time: 0:00:02\n",
            "\n",
            "------------------------------\n",
            "Beginning epoch 5 of 6\n",
            "Average Training Loss: 1.4214116679959827. Epoch time: 0:01:34\n",
            "\n",
            "Validation loss: 4.64016592502594. Validation Time: 0:00:02\n",
            "\n",
            "------------------------------\n",
            "Beginning epoch 6 of 6\n",
            "Average Training Loss: 1.0224337253305646. Epoch time: 0:01:34\n",
            "\n",
            "Validation loss: 5.133324880599975. Validation Time: 0:00:02\n",
            "\n",
            "------------------------------\n",
            "Total training took 0:09:39\n"
          ]
        }
      ],
      "source": [
        "total_t0 = time.time()\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "for epoch_i in range(epochs):\n",
        "  print(f'Beginning epoch {epoch_i+1} of {epochs}')\n",
        "\n",
        "  t0 = time.time()\n",
        "  total_train_loss = 0\n",
        "  model.train()\n",
        "\n",
        "  # Labels are shifted by 1 timestep\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_labels = batch[0].to(device)\n",
        "    b_masks = batch[1].to(device)\n",
        "\n",
        "    model.zero_grad()\n",
        "\n",
        "    outputs = model(b_input_ids,\n",
        "                    labels=b_labels,\n",
        "                    attention_mask=b_masks)\n",
        "    \n",
        "    loss = outputs[0]\n",
        "\n",
        "    batch_loss = loss.item()\n",
        "    total_train_loss += batch_loss\n",
        "\n",
        "    # Sampling every x steps\n",
        "    if step != 0 and step % sample_every == 0:\n",
        "\n",
        "      elapsed = format_time(time.time()-t0)\n",
        "      print(f'Batch {step} of {len(train_dataloader)}. Loss: {batch_loss}. Time: {elapsed}')\n",
        "\n",
        "      model.eval()\n",
        "\n",
        "      sample_outputs = model.generate(\n",
        "                                    bos_token_id=random.randint(1,30000),\n",
        "                                    do_sample=True,   \n",
        "                                    top_k=50, \n",
        "                                    max_length = 25,\n",
        "                                    top_p=0.95, \n",
        "                                    num_return_sequences=1\n",
        "                                )\n",
        "      for i, sample_output in enumerate(sample_outputs):\n",
        "        print(f'Example ouput: {tokenizer.decode(sample_output, skip_special_tokens=True)}')\n",
        "      print()\n",
        "\n",
        "      model.train()\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "\n",
        "  avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "  training_time = format_time(time.time()-t0)\n",
        "  print(f'Average Training Loss: {avg_train_loss}. Epoch time: {training_time}')\n",
        "  print()\n",
        "\n",
        "  t0 = time.time()\n",
        "  model.eval()\n",
        "\n",
        "  total_eval_loss = 0\n",
        "  nb_eval_steps = 0\n",
        "\n",
        "  for batch in val_dataloader:\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_labels = batch[0].to(device)\n",
        "    b_masks = batch[1].to(device)\n",
        "        \n",
        "    with torch.no_grad():        \n",
        "\n",
        "        outputs  = model(b_input_ids,  \n",
        "                         attention_mask = b_masks,\n",
        "                         labels=b_labels)\n",
        "          \n",
        "        loss = outputs[0]  \n",
        "            \n",
        "    batch_loss = loss.item()\n",
        "    total_eval_loss += batch_loss   \n",
        "\n",
        "  avg_val_loss = total_eval_loss / len(val_dataloader)  \n",
        "  val_time = format_time(time.time() - t0)    \n",
        "  print(f'Validation loss: {avg_val_loss}. Validation Time: {val_time}')\n",
        "  print()\n",
        "\n",
        "  # Record all statistics from this epoch.\n",
        "  training_stats.append(\n",
        "      {\n",
        "          'epoch': epoch_i + 1,\n",
        "          'Training Loss': avg_train_loss,\n",
        "          'Valid. Loss': avg_val_loss,\n",
        "          'Training Time': training_time,\n",
        "          'Validation Time': val_time\n",
        "      }\n",
        "  )\n",
        "  print(\"------------------------------\")\n",
        "\n",
        "print(f'Total training took {format_time(time.time()-total_t0)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "cc62c28a",
      "metadata": {
        "id": "cc62c28a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "879a706a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "879a706a",
        "outputId": "aa228806-b5b4-476a-b816-5453c3e07726"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: the first thing i found\n",
            "in my old garden—\n",
            "the cherrytree.\n",
            "\n",
            "\n",
            "1: the moon\n",
            "in every puddle\n",
            "a crushed whiskey bottle.\n",
            "\n",
            "\n",
            "2: i have no proof but i tell you\n",
            "there were leadlight windows here once barred\n",
            "they cast a little striped light on the night sky.\n",
            "\n",
            "\n",
            "3: the old man's wrinkled face\n",
            "and saffron beauty buried \n",
            "behind his painted door.\n",
            "\n",
            "\n",
            "4: the old kettle\n",
            "still shines\n",
            "in the rain.\n",
            "\n",
            "\n",
            "5: i got a space pack on and put it in my pocket\n",
            "i'm carrying my space\n",
            "with my space hunger.\n",
            "\n",
            "\n",
            "6: i don't believe in an afterlife she says\n",
            "but after k\n",
            "died i thought i might go after her.\n",
            "\n",
            "\n",
            "7: my daughter's graduation\n",
            "the last time\n",
            "I saw her.\n",
            "\n",
            "\n",
            "8: the last line should strike like a lover's complaint\n",
            "and should thus be left only: the lover must bear it and deserve it\n",
            "but the lover must bear it not.\n",
            "\n",
            "\n",
            "9: the smell of rain\n",
            "from somewhere else\n",
            "even more so.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "\n",
        "prompt = \"<|startoftext|>\"\n",
        "\n",
        "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to(device)\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "                                generated, \n",
        "                                do_sample=True,   \n",
        "                                top_k=20, \n",
        "                                max_length = 40,\n",
        "                                top_p=0.8, \n",
        "                                num_return_sequences=10\n",
        "                                )\n",
        "\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "prompt = \"<|startoftext|>\"\n",
        "\n",
        "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to(device)\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "                                generated, \n",
        "                                do_sample=True,   \n",
        "                                top_k=30, \n",
        "                                max_length = 25,\n",
        "                                top_p=0.7, \n",
        "                                num_return_sequences=15\n",
        "                                )\n",
        "\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
      ],
      "metadata": {
        "id": "O9TKves6f8c2"
      },
      "id": "O9TKves6f8c2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa228806-b5b4-476a-b816-5453c3e07726",
        "id": "21dQszhsf-4m"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: the first thing i found\n",
            "in my old garden—\n",
            "the cherrytree.\n",
            "\n",
            "\n",
            "1: the moon\n",
            "in every puddle\n",
            "a crushed whiskey bottle.\n",
            "\n",
            "\n",
            "2: i have no proof but i tell you\n",
            "there were leadlight windows here once barred\n",
            "they cast a little striped light on the night sky.\n",
            "\n",
            "\n",
            "3: the old man's wrinkled face\n",
            "and saffron beauty buried \n",
            "behind his painted door.\n",
            "\n",
            "\n",
            "4: the old kettle\n",
            "still shines\n",
            "in the rain.\n",
            "\n",
            "\n",
            "5: i got a space pack on and put it in my pocket\n",
            "i'm carrying my space\n",
            "with my space hunger.\n",
            "\n",
            "\n",
            "6: i don't believe in an afterlife she says\n",
            "but after k\n",
            "died i thought i might go after her.\n",
            "\n",
            "\n",
            "7: my daughter's graduation\n",
            "the last time\n",
            "I saw her.\n",
            "\n",
            "\n",
            "8: the last line should strike like a lover's complaint\n",
            "and should thus be left only: the lover must bear it and deserve it\n",
            "but the lover must bear it not.\n",
            "\n",
            "\n",
            "9: the smell of rain\n",
            "from somewhere else\n",
            "even more so.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "\n",
        "prompt = \"<|startoftext|>\"\n",
        "\n",
        "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to(device)\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "                                generated, \n",
        "                                do_sample=True,   \n",
        "                                top_k=20, \n",
        "                                max_length = 15,\n",
        "                                top_p=0.5, \n",
        "                                num_return_sequences=5\n",
        "                                )\n",
        "\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
      ],
      "id": "21dQszhsf-4m"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9bca485",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9bca485",
        "outputId": "b562d981-7386-47cb-f9d4-35304b3daee6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/My Drive/Work/GPTmodels/GPT2Tuned/tokenizer_config.json',\n",
              " '/content/drive/My Drive/Work/GPTmodels/GPT2Tuned/special_tokens_map.json',\n",
              " '/content/drive/My Drive/Work/GPTmodels/GPT2Tuned/vocab.json',\n",
              " '/content/drive/My Drive/Work/GPTmodels/GPT2Tuned/merges.txt',\n",
              " '/content/drive/My Drive/Work/GPTmodels/GPT2Tuned/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "output_dir = \"/content/drive/My Drive/Work/GPTmodels/GPT2Tuned\"\n",
        "\n",
        "# Save generated poems\n",
        "# sample_outputs = model.generate(\n",
        "#                                 generated, \n",
        "#                                 do_sample=True,   \n",
        "#                                 top_k=50, \n",
        "#                                 max_length = 300,\n",
        "#                                 top_p=0.95, \n",
        "#                                 num_return_sequences=25\n",
        "#                                 )\n",
        "\n",
        "# with open(os.path.join(output_dir, 'generated_poems.txt'), \"w\") as outfile:\n",
        "#   for i, sample_output in enumerate(sample_outputs):\n",
        "#     outfile.write(tokenizer.decode(sample_output, skip_special_tokens=True)+\"\\n\\n\")\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(training_stats, os.path.join(output_dir, 'training_args.bin'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12f9f246",
      "metadata": {
        "id": "12f9f246"
      },
      "outputs": [],
      "source": [
        "# Loading saved model\n",
        "model_dir = \"/content/drive/My Drive/Work/GPTmodels/GPT2Tuned\"\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained(model_dir)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_dir)\n",
        "\n",
        "# model = GPT2LMHeadModel.from_pretrained(\"prajwalcr/poetry-joy_gpt2\")\n",
        "# tokenizer = GPT2Tokenizer.from_pretrained(\"prajwalcr/poetry-joy_gpt2\")\n",
        "model.to(device)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}